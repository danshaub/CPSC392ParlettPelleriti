{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split # simple TT split cv\n",
    "from sklearn.model_selection import KFold # k-fold cv\n",
    "from sklearn.model_selection import LeaveOneOut #LOO cv\n",
    "from sklearn.model_selection import cross_val_score # cross validation metrics\n",
    "from sklearn.model_selection import cross_val_predict # cross validation metrics\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're generating fake data that we're going to use to predict whether a customer at Target signs up for a rewards program (`rewards_signup`) based on \n",
    "\n",
    "* their age (`age`)\n",
    "* their income (`income_in_k`), and \n",
    "* whether they made a purchase (`previous_purchase`) in the last month\n",
    "\n",
    "Remember, each time you use a np.random.XXXX function, you'll get *different* fake data, because it's randomly generated. Try it out! If you want your data to come out the SAME each time, add the line `np.random.seed(XXXX)` at the top of the next cell, where `XXXX` is any integer you want like 42, 8675309, or 1234."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Logistic Regression Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100 # number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables---\n",
    "np.random.seed(42)\n",
    "\n",
    "age = np.round(np.random.normal(37, 5, size = n),0)\n",
    "income_in_k = np.round(np.random.normal(100,10, size = n), 2)\n",
    "previous_purchase = np.random.binomial(1,0.5, size = n)\n",
    "\n",
    "# set true coefficients---\n",
    "a = 0.1 # age\n",
    "i = 0.03 # income\n",
    "p = 2.6 # previous purchase\n",
    "\n",
    "inter = -8.2 # intercept\n",
    "\n",
    "error = np.random.normal(0,0.25,size = n) # random error\n",
    "\n",
    "# probability they signed up for reward program---\n",
    "ex = np.exp(inter + a*age + i*income_in_k + p*previous_purchase + error) #predicted odds\n",
    "reward_signup = (ex/(1 + ex)) #predicted probability\n",
    "\n",
    "\n",
    "# you may also see the log reg formula like this---\n",
    "# reward_signup = 1/(1 + (1/ex)) \n",
    "\n",
    "\n",
    "# yes/no did they sign up---\n",
    "y = np.random.binomial(1, reward_signup) #generate random values\n",
    "\n",
    "\n",
    "# make DataFrame---\n",
    "df = pd.DataFrame({\"age\": age,\n",
    "                  \"income\": income_in_k,\n",
    "                  \"previous_purchase\": previous_purchase,\n",
    "                  \"signed_up\": y})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (878791)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot\n",
    "(ggplot(df, aes(x = \"y\")) + geom_bar(color = \"black\") +\n",
    "theme_minimal() + labs(title = \"Did you sign up for the Rewards Program?\", x = \"\", y = \"\") + \n",
    "theme(panel_grid_major = element_blank()) +\n",
    "scale_x_continuous(breaks = [0,1], labels = [\"No\", \"Yes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Fit a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"age\", \"income\", \"previous_purchase\"]\n",
    "X = df[features]\n",
    "y = df[[\"signed_up\"]] #if you don't have the extra brackets, y will be a series instead of an array and throw an error\n",
    "\n",
    "\n",
    "# create + fit a logistic regression\n",
    "#########################################\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# zscore = StandardScaler()\n",
    "# zscore.fit(X_train)\n",
    "\n",
    "# Xz_train = zscore.transform(X_train)\n",
    "# Xz_test = zscore.transform(X_test)\n",
    "\n",
    "myLogit = LogisticRegression()\n",
    "myLogit.fit(X, y)\n",
    "\n",
    "# predictedVals = myLogit.predict(Xz_test)\n",
    "#########################################\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08986586 0.07262218 1.75040197]] [-11.8466095]\n"
     ]
    }
   ],
   "source": [
    "# grab the coefficients from the model and store them in a data frame----\n",
    "\n",
    "print(myLogit.coef_, myLogit.intercept_)\n",
    "#########################################\n",
    "coefs = pd.DataFrame({\"Coef\": myLogit.coef_[:,0]})\n",
    "# coefs = coefs.append({\"Coef\": myLogit.intercept_, \"Name\": \"intercept\"}, ignore_index = True)\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient of age is 0.089866, and the intercept is -11.846610. The coefficient of age indicates that as length increases by 1 year, we expect the log odds of signing up to increase by 0.0899 .\n",
    "\n",
    "### *Question*\n",
    "\n",
    "Compare that to the TRUE population values we set above (hint: print `a` and `inter`). How close are the numbers from *this* logistic regression to the true values? What do you think will happen if we created another random sample? 100 random samples?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "What is the interpretation of the income coefficient?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Log Odds, Odds, and Probabilities\n",
    "\n",
    "The coefficients for **log**istic regression are in terms of **log** odds. While this means that our regression formula is nice and easy to solve, log odds can be tough to wrap your head around. Often, we exponentiate the coefficients (using `np.exp()`) to get our coefficients in terms of odds rather than log odds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Odds\n",
    "\n",
    "We'll grab our coefficients from `coef` and exponentiate them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# add a new colum to your dataframe coef that has the coefficients in terms of ODDS\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way you interpret coefficients in their exponentiated (odds) form is similar to how you interpret them in their raw form.\n",
    "\n",
    "Here's an example of the difference:\n",
    "\n",
    "**Raw Coefficient**: And increase in 1 year of age is associated with a 0.0899 increase in the log odds of signing up for the rewards program.\n",
    "\n",
    "**Exponentiated Coefficient**: An increase in 1 year of age is associated with a 1.094x increase in the odds of signing up for the rewards program.\n",
    "\n",
    "However, the math is slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "What is the interpretation of the age and income coefficients in terms of *odds*?\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 More Odds\n",
    "\n",
    "Using the coefficients generated by our model, let's look at how the predicted log odds and odds change when we play around with the values for `age`, `income`, and `previous_purchase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the LOG ODDS based on coefs and predictor values\n",
    "\n",
    "def calc_lo(age,income, previous_purchase, coefs):\n",
    "    return(np.sum(np.array([age,income, previous_purchase, 1]) * coefs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Odds for Original: 0.5353084347862271\n",
      "Log Odds for +1 year : 0.6251742913210787\n",
      "\n",
      "The difference in log odds is: 0.08986585653485157\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "age_value = 40\n",
    "#########################################\n",
    "\n",
    "# predicted logOdds for a 40 year old, with 121k income, no previous purchase\n",
    "lo = calc_lo(age_value,121,0, coef[\"Coef\"])\n",
    "print(\"Log Odds for Original: \" + str(lo))\n",
    "\n",
    "\n",
    "# predicted logOdds for a 41 year old, with 121k income, no previous purchase\n",
    "lo2 = calc_lo(age_value + 1,121,0, coef[\"Coef\"])\n",
    "print(\"Log Odds for +1 year : \" + str(lo2))\n",
    "\n",
    "# change in log odds for 1 year increase in age\n",
    "print(\"\\nThe difference in log odds is: \"  + str(lo2-lo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "The change in log odds for adding 1 year to a customer's age is equal to the coefficient for `age` from our model (As expected). Play around with the above code using different ages. How does the difference in predicted log odds change in response to a 1 year increase in age? Does it always change by the same amount?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "Now let's look at the odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the ODDS based on coefs and predictor values\n",
    "# odds = e^lo\n",
    "\n",
    "def calc_o(age,income, previous_purchase, coefs):\n",
    "    return(np.exp(np.sum(np.array([age,income, previous_purchase, 1]) * coefs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds for Original: 1.7079749599126537\n",
      "Odds for +1 year : 1.8685716048661796\n",
      "\n",
      "The difference in odds is: 0.16059664495352588\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "age_value = 40\n",
    "#########################################\n",
    "\n",
    "# predicted odds for a 40 year old, with 121k income, no previous purchase\n",
    "o = calc_o(age_value,121,0, coef[\"Coef\"])\n",
    "print(\"Odds for Original: \" + str(o))\n",
    "\n",
    "\n",
    "# predicted odds for a 41 year old, with 121k income, no previous purchase\n",
    "o2 = calc_o(age_value + 1,121,0, coef[\"Coef\"])\n",
    "print(\"Odds for +1 year : \" + str(o2))\n",
    "\n",
    "# change in odds for 1 year increase\n",
    "print(\"\\nThe ratio of odds is: \"  + str(o2/o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try with a 27 year old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_o' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5fe6d6b2b3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# predicted odds for a 27 year old, with 121k income, no previous purchase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Coef\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Odds for Original: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calc_o' is not defined"
     ]
    }
   ],
   "source": [
    "age_value = 27\n",
    "\n",
    "# predicted odds for a 27 year old, with 121k income, no previous purchase\n",
    "o = calc_o(age_value,121,0, coef[\"Coef\"])\n",
    "print(\"Odds for Original: \" + str(o))\n",
    "\n",
    "\n",
    "# predicted odds for a 28 year old, with 121k income, no previous purchase\n",
    "o2 = calc_o(age_value + 1,121,0, coef[\"Coef\"])\n",
    "print(\"Odds for +1 year : \" + str(o2))\n",
    "\n",
    "# change in odds for 1 year increase\n",
    "print(\"\\nThe ratio of odds is: \"  + str(o2/o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "The change in the ratio of odds for adding 1 year to a customer's age is equal to the exponentiated coefficient for `age` from our model (As expected). Now try plugging in some other ages. Is the change in the ratio (`o2/o`) *always* about 1.094 (there may be a small amount of rounding error)?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odds for Original: 0.6953429300614954\n",
      "Odds for +1 year : 0.7607242993912549\n",
      "\n",
      "The change in odds is: 1.0940275172194203\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "# play around with different ages\n",
    "age_value = 30\n",
    "#########################################\n",
    "\n",
    "# predicted odds for a 30 year old, with 121k income, no previous purchase\n",
    "o = calc_o(age_value,121,0, coef[\"Coef\"])\n",
    "print(\"Odds for Original: \" + str(o))\n",
    "\n",
    "\n",
    "# predicted odds for a 31 year old, with 121k income, no previous purchase\n",
    "o2 = calc_o(age_value + 1,121,0, coef[\"Coef\"])\n",
    "print(\"Odds for +1 year : \" + str(o2))\n",
    "\n",
    "# change in odds for 1 year increase\n",
    "print(\"\\nThe change in odds is: \"  + str(o2/o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Probabilities are Problematic\n",
    "\n",
    "If you work with people who aren't familiar with them, even odds can seem tricky to interpret. So people will often ask you to transform odds into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the probability based on coefs and predictor values\n",
    "\n",
    "def calc_p(age,income, previous_purchase, coefs):\n",
    "    odds = np.exp(np.sum(np.array([age,income, previous_purchase, 1]) * coefs))\n",
    "    return(odds/(1+odds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for Original: 0.6307203667672558\n",
      "Probability for +1 year : 0.6513944437351249\n",
      "\n",
      "The difference in probability is: 0.02067407696786905\n",
      "The change in probability is: 1.032778514944481\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "age_value = 40\n",
    "#########################################\n",
    "\n",
    "# predicted prob for a 40 year old, with 121k income, no previous purchase\n",
    "o = calc_p(age_value,121,0, coef[\"Coef\"])\n",
    "print(\"Probability for Original: \" + str(o))\n",
    "\n",
    "\n",
    "# predicted prob for a 41 year old, with 121k income, no previous purchase\n",
    "o2 = calc_p(age_value + 1,121,0, coef[\"Coef\"])\n",
    "print(\"Probability for +1 year : \" + str(o2))\n",
    "\n",
    "# change in prob for 1 year increase\n",
    "print(\"\\nThe difference in probability is: \"  + str(o2-o))\n",
    "print(\"The change in probability is: \"  + str(o2/o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "Play around with different ages. Is either the *difference* or the *ratio* of the probabilities constant no matter what age you start with?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for Original: 0.04481655423032447\n",
      "Probability for +1 year : 0.04882479638419229\n",
      "\n",
      "The difference in probability is: 0.004008242153867823\n",
      "The change in probability is: 1.0894366428366709\n"
     ]
    }
   ],
   "source": [
    "def calc_p(age,income, previous_purchase, coefs):\n",
    "    odds = np.exp(np.sum(np.array([age,income, previous_purchase, 1]) * coefs))\n",
    "    return(odds/(1+odds))\n",
    "\n",
    "#########################################\n",
    "# play around with age values\n",
    "age_value = 0 \n",
    "#########################################\n",
    "\n",
    "# predicted prob for a ??? year old, with 121k income, no previous purchase\n",
    "o = calc_p(age_value,121,0, coef[\"Coef\"])\n",
    "print(\"Probability for Original: \" + str(o))\n",
    "\n",
    "\n",
    "# predicted prob for a ??? +1 year old, with 121k income, no previous purchase\n",
    "o2 = calc_p(age_value + 1,121,0, coef[\"Coef\"])\n",
    "print(\"Probability for +1 year : \" + str(o2))\n",
    "\n",
    "# change in prob for 1 year increase\n",
    "print(\"\\nThe difference in probability is: \"  + str(o2-o))\n",
    "print(\"The change in probability is: \"  + str(o2/o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Moral of the story probabilities can make more intuitive sense, but the amount a 1 unit increase in a predictor changes the predicted probability is *NOT CONSTANT*, it depends heavily on the values of the predictor of interest and all other predictors. If you're going to report in terms of probabilities you MUST be specific about what values all your predictors have.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Accuracy Across Simulations\n",
    "\n",
    "Now, let's use this function to generate *many* fake datasets that all have the same true coefficients. Similar to adding mse in the Linear Regression example, change the below function to also record the accuracy for each model and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(n = 100, age = 0.1, i = 0.03, p = 2.6, inter = -8.2):\n",
    "\n",
    "    age = np.round(np.random.normal(37, 5, size = n),0)\n",
    "    income_in_k = np.round(np.random.normal(100,10, size = n), 2)\n",
    "    previous_purchase = np.random.binomial(1,0.5, size = n)\n",
    "    \n",
    "    error = np.random.normal(0,0.25,size = n) # random error\n",
    "\n",
    "    # probability they signed up for reward program---\n",
    "    ex = np.exp(inter + a*age + i*income_in_k + p*previous_purchase + error)\n",
    "    reward_signup = (ex/(1 + ex)) \n",
    "\n",
    "\n",
    "    # you may also see the log reg formula like this---\n",
    "    # reward_signup = 1/(1 + (1/ex)) \n",
    "\n",
    "\n",
    "    # yes/no did they sign up---\n",
    "    y = np.random.binomial(1, reward_signup)\n",
    "    \n",
    "    # make DataFrame---\n",
    "    df = pd.DataFrame({\"age\": age,\n",
    "                      \"income\": income_in_k,\n",
    "                      \"previous_purchase\": previous_purchase,\n",
    "                      \"signed_up\": y})\n",
    "    \n",
    "    features = [\"age\", \"income\", \"previous_purchase\"]\n",
    "    X = df[features]\n",
    "    y = df[[\"signed_up\"]] #if you don't have the extra brackets, y will be a series instead of an array and throw an error\n",
    "\n",
    "    #########################################\n",
    "    # run + fit a logistic regression\n",
    "\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    ##### ADD Acc CODE HERE ######\n",
    "    acc = ######\n",
    "    ###############################\n",
    "    \n",
    "    \n",
    "    # grab the coefficients from the model and store them in a data frame\n",
    "    coef = pd.DataFrame({\"Coef\": lr.coef_[0], \"Names\": features})\n",
    "    coef = coef.append({\"Coef\": lr.intercept_[0], \"Names\": \"intercept\"}, ignore_index = True)\n",
    "    \n",
    "    return({\"coef\": coef, \"data\": df, \"acc\": ######}) # dont forget to return accuracy!!#########################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "Simulate 500 datasets and plot a histogram of the accuracies. Remember, all these datasets are generated the exact same way and all have the exact same true values and error. What does the shape and spread of the histogram tell you about the accuracy values you observe when running a single model on a single (non-simulated) dataset?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" alt=\"Q\" width = 200px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "#run regression simulation 500 times\n",
    "iWouldRun500Regressions = [logisticRegression() for x in range(0,500)]\n",
    "\n",
    "# grab coefficients from 500 simulations\n",
    "coef_df = pd.concat([x[\"coef\"] for x in iWouldRun500Regressions])\n",
    "\n",
    "# grab coefficients from 500 simulations\n",
    "data_df = pd.concat([x[\"data\"] for x in iWouldRun500Regressions])\n",
    "\n",
    "# grab acc from 500 simulations\n",
    "acc_df = pd.DataFrame({\"acc\": [x[\"data\"] for x in iWouldRun500Regressions]})\n",
    "\n",
    "# number simulations 0:499\n",
    "data_df[\"simulation_no\"] = sorted(list(range(0,500))* n)\n",
    "coef_df[\"simulation_no\"] = sorted(list(range(0,500))*(len(features) + 1))\n",
    "acc_df[\"simulation_no\"] = list(range(0,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram or density plot of the different accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram or density plot of the different coefficient values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
