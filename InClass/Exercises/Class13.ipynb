{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should only need these 3 imports to complete this assignment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Together\n",
    "\n",
    "## 0.1 Entropy\n",
    "\n",
    "Entropy is a measure of disorder/chaos. We want ordered and organized data in the leaf nodes of our decision trees. So we want LOW entropy. **Entropy** is defined as:\n",
    "\n",
    "$$ E = -\\sum_1^N p_i* log_2(p_i) $$\n",
    "\n",
    "Where $N$ is the number of categories or labels in our outcome variable.\n",
    "\n",
    "This is compared to **gini impurity** which is:\n",
    "\n",
    "$$GI = 1 - \\sum_1^N p_i^2$$\n",
    "\n",
    "(if you're super into decision trees, check out this paper [Theoretical comparison between the Gini Index and\n",
    "Information Gain criteria](https://www.unine.ch/files/live/sites/imi/files/shared/documents/papers/Gini_index_fulltext.pdf))\n",
    "\n",
    "### *Question*\n",
    "\n",
    "WHY do we want the leaf nodes of our tree to be ordered (have low entropy or impurity?)?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Measures of Chaos for a Split\n",
    "\n",
    "When you split a node, we now have two new nodes. In order to calculate the chaos (entropy or gini impurity) of the split, we have to calculate the chaos (entropy or gini impurity) for EACH of the new nodes and then calculate the weighted average chaos (entropy or gini impurity).  \n",
    "\n",
    "The reason we weight each node differently in this calculation, is because if a node has more data in it, than it has more impact, and therefore its measure of chaos (entropy or gini impurity) should count more.\n",
    "\n",
    "In general, once you've calculated the chaos (entropy or gini impurity) for each of the new nodes, you'll use this formula to calculate the weighted average:\n",
    "\n",
    "\n",
    "$$ WC = (\\frac{N_L}{Total}* C_L) + (\\frac{N_R}{Total}* C_R)$$\n",
    "\n",
    "Where $N_L$ is the number of data points in the Left Node, $N_R$ is the number of data points in the Right Node, and $Total$ is the total number of data points in that split. $C_R$ and $C_L$ are the chaos measure (entropy of gini impurity) for the right and left nodes, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Measures of Chaos\n",
    "\n",
    "## 1.1 Gini Impurity\n",
    "\n",
    "Use python and numpy to write two functions, as described in the comments below.\n",
    "<img src = \"https://drive.google.com/uc?id=1MQEeJDxxcV8zmhzBgaDZ2QY0Ng8z8hz8\" width = 300px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ############\n",
    "\n",
    "\n",
    "def gini():\n",
    "    # this function calculates the gini impurity for ONE node (left, right, or root!)\n",
    "    # this function should take in the right and left node counts as arguments\n",
    "    # and calculate the gini impurity for that node based on the formula above\n",
    "    # return the impurity for the node.\n",
    "    \n",
    "    pass\n",
    "\n",
    "def gini_split():\n",
    "    \n",
    "    # this function takes FOUR arguments: LNP, LNN, RNP, and RNN and calculates\n",
    "    # the gini impurity for each node (by calling gini()) and then calculates\n",
    "    # the weighted average of the impurity in each node.\n",
    "    # return the impurity for the split.\n",
    "    \n",
    "    pass\n",
    "\n",
    "### YOUR CODE HERE ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to test your code, if it prints True, you got the right answer\n",
    "\n",
    "abs(gini(10,5,2,12) - 0.3481116584564861) <= 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Entropy\n",
    "\n",
    "Use python and numpy to write two functions, as described by the comments below. If you want to read more about entropy, see this [article](https://bricaud.github.io/personal-blog/entropy-in-decision-trees/).\n",
    "\n",
    "hint: `np.log2()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###############\n",
    "\n",
    "def entropy():\n",
    "    # this function calculates the entropy for ONE node (left, right, or root!)\n",
    "    # this function should take in the right and left node counts as arguments\n",
    "    # and calculate the entropy for that node based on the formula above\n",
    "    pass\n",
    "\n",
    "def entropy_split():\n",
    "    # this function takes FOUR arguments: LNP, LNN, RNP, and RNN and calculates\n",
    "    # the entropy for each node (by calling entropy()) and then calculates\n",
    "    # the weighted average of the entropy in each node.\n",
    "    # return the entropy for the split.\n",
    "    pass\n",
    "\n",
    "### YOUR CODE HERE ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to test your code, if it prints True, you got the right answer\n",
    "\n",
    "abs(entropy(10,5,2,12) - 0.7606157383093077) <= 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build a Categorical Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mushroom Data------------------------------------\n",
    "import pandas as pd\n",
    "\n",
    "# see this site for what variables mean: http://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "mush = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\")\n",
    "\n",
    "mush.columns = ['poison','cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size',\n",
    "                'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring',\n",
    "                'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number','ring-type',\n",
    "                'spore-print-color', 'population', 'habitat']\n",
    "\n",
    "mush.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your sanity, let's restrict our dataset to 3 predictor variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mush_small = mush[[\"poison\", \"bruises\", \"gill-size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar plot of edible/poisonous mushrooms############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar plot of bruised/not-bruised mushrooms############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bar plot of broad/narrow gilled mushrooms############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Build!\n",
    "\n",
    "Use the functions you built earlier to build a decision tree that classifies each data point as either edible (`e`) or poisonous (`p`). You can choose to either use entropy or gini impurity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Layer 1\n",
    "\n",
    "Choose which variable to use to split the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries of possible splits############\n",
    "# Try getting something like this for the root node: {'e': 4208, 'p': 3915}\n",
    "# BUT CALCULATE IT FROM THE DATA, DON'T JUST HARDCODE THAT DICTIONARY\n",
    "\n",
    "\n",
    "# Something like this for splitting on bruise: \n",
    "# {'f': {'e': 4748, 'p': 3292}, 't': {'e': 3375, 'p': 623}}\n",
    "# BUT CALCULATE IT FROM THE DATA, DON'T JUST HARDCODE THAT DICTIONARY\n",
    "\n",
    "\n",
    "# Something like this for splitting on gill: \n",
    "# {'b': {'e': 5612, 'p': 1692}, 'n': {'e': 2511, 'p': 2223}}\n",
    "# BUT CALCULATE IT FROM THE DATA, DON'T JUST HARDCODE THAT DICTIONARY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate impurity/entropy of each possible split using your functions###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose which split improves prediction most############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question*\n",
    "\n",
    "Does splitting the root node improve the tree? How can you tell?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1.2 Create Classifications\n",
    "\n",
    "Pretend that this decision stump (a decision tree with only one layer) is your final tree. Generate the classification for each data point and store it in `mush_small`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Calculate Accuracy\n",
    "\n",
    "Count how often your model made the correct classification. How well did your model do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Chaos\n",
    "\n",
    "### *Question*\n",
    "\n",
    "When would Gini Impurity be 0? When would Entropy be 0? What does that mean about our tree/node?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
