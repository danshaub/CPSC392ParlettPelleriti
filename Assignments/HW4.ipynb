{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import StandardScaler #Z-score variables\n",
    "\n",
    "from sklearn.model_selection import train_test_split # simple TT split cv\n",
    "from sklearn.model_selection import KFold # k-fold cv\n",
    "from sklearn.model_selection import LeaveOneOut #LOO cv\n",
    "from sklearn.model_selection import cross_val_score # cross validation metrics\n",
    "from sklearn.model_selection import cross_val_predict # cross validation metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Ensemble\n",
    "A common theme in applied Machine Learning is *The Ensemble Method*. Ensemble methods use multiple machine learning models at once. The idea is that using ensembles improves predictive performance, because even though some of the models will sometimes be incorrect, it's unlikely that a MAJORITY of the models in our ensemble will all be incorrect in the exact same way each time. Therefore in aggregate, we will get a more accurate ensemble model.\n",
    "\n",
    "Each model predicts a category and \"votes\" about which category a data point should be in (ensemble methods also work for continuous outcomes, but here we'll focus on categorical ones). Models \"vote\" for whichever category it predicts for that data point. \n",
    "\n",
    "To combat overfitting and reduce potential *over-reliance* on a small number of features, we can use the two following techniques when creating models for our ensemble:\n",
    "\n",
    "* **Bagging (Bootstrap Aggregating)**: Instead of using all of the *rows* in our training data to train each model in our sample we use **bootstrapping** to choose which rows we will include when training.\n",
    "    * **Bootstrapping** is when you randomly sample data points *with replacement*, meaning that a row can be included in your bootstrapped sample *more* than once, OR not at all.\n",
    "* **Random Feature Selection**: Instead of using all the available features/predictors in our dataset for every model, for each model we randomly choose a different subset of features to use when training. This helps our ensemble generalize, because it doesn't become overly reliant on one feature (since that feature might not appear in every model).\n",
    "\n",
    "Because a predictor won't be in EVERY model in the ensemble, it prevents the ensemble from over-relying on that predictor, while still using it in SOME of the models.\n",
    "\n",
    "While ensemble methods take a lot of computational power (you're training MANY models instead of just one), in practice they're often really useful. An incredibly popular ensemble method is the **Random Forest** which is an ensemble method that uses a bunch of decision trees along with Bagging and Random Feature selection to generate the ensemble.\n",
    "\n",
    "To simplify: a Random Forest is a BUNCH of decision trees. Each decision tree uses a different, randomly selected group of rows/data points, and predictors/columns. Each tree gets a \"vote\" about which category a data point should be in. Whichever category gets the most votes, is the one chosen by our Random Forest.\n",
    "\n",
    "## 1.1 Building a Random Forest\n",
    "\n",
    "Let's build a tiny random forest function of our own! Write a function `Forest()` that takes in 6 arguments:\n",
    "\n",
    "* `n_samples` (**integer**): number of bootstrapped samples to use to train each decision tree.\n",
    "* `n_features` (**integer**): number of randomly selected features from your data set to use when training.\n",
    "* `n_trees` (**integer**): how many decision trees to create for the ensemble.\n",
    "* `max_d` (**integer**): the max_depth for all of your trees.\n",
    "* `X` (**data frame**): the *already* z-scored predictor data to be used.\n",
    "* `y` (**data frame**): the outcome data to be used (`X` and `y` are the same length, and the $i^{th}$ element of `X` corresponds to the $i^{th}$ element of `y`)\n",
    "\n",
    "The function should:\n",
    "\n",
    "1. use a for loop to create `n_trees` models and store them in a list called `forest` (yes! You can store fitted decision trees in a list!)\n",
    "2. For each model you should choose use bootstrapping to sample `n_samples` data points to train each model. Remember that boostrapping means sampling WITH replacement (hint: try using [`np.random.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) to randomly select (*with replacement*) which row numbers/indices to use.\n",
    "3. For each model, randomly select `n_features` to use to train your model. (hint: try using [`np.random.choice`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) to randomly select (*withOUT replacement*) which predictor indices to use.\n",
    "4. For all models, make sure you set the `max_depth`.\n",
    "5. For each model, train the model (no need to use model validation, and assume X is already z-scored).\n",
    "6. Return a list (`forest`) of dictonaries that look like this (where `tree` is your trained model and `samples_index` is an array of indices for the features/predictors you selected):\n",
    " ```{\"tree\": tree, \"feats\": samples_index}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: I'll Just Leave this hint here...\n",
    "\n",
    "## simple bootstrapping example of names dataframe \n",
    "np.random.seed(1234)\n",
    "\n",
    "names = [\"Alex\", \"Charlie\", \"Addison\", \"James\", \"Blake\", \"Greg\", \"Daniel\", \"Susan\", \"Erik\", \"Georgia\", \"Kayne\",\n",
    "         \"Lydia\", \"Peter\", \"Jane\", \"Jasper\", \"Link\", \"Rhett\", \"John\", \"Miranda\", \"Luke\", \"Leia\", \"Janet\", \"Jung\",\n",
    "         \"Anthony\", \"Mark\", \"Torrence\", \"Bonnie\", \"Rudy\", \"Lisa\", \"Bart\", \"Tina\", \"Marie\"]\n",
    "\n",
    "names_df = pd.DataFrame({\"name\": names, \"age\": np.random.randint(17,27, len(names))})\n",
    "names_df\n",
    "\n",
    "names_index = np.random.choice(range(0,len(names)), 15, replace = True)\n",
    "names_boot = names_df.iloc[names_index]\n",
    "\n",
    "# notice how Lisa shows up more than once?\n",
    "\n",
    "names_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "def Forest(X, y, n_samples = 1000, n_features = 5, n_trees = 100, max_d = 5):\n",
    "    forest = []\n",
    "    \n",
    "    # create n_trees models\n",
    "    for i in range(0,n_trees):\n",
    "        \n",
    "        # 1. randomly bootstrap `n_samples` datapoints by sampling\n",
    "        # row indices from X WITH replacement using np.random.choice()\n",
    "        \n",
    "        \n",
    "        # 2. randomly choose `n_features` features by sampling column indices \n",
    "        # from X WITHOUT replacement using np.random.choice()\n",
    "\n",
    "        \n",
    "        # 3. subset X and y to only include the rows and (for X) features/predictors\n",
    "        # that were selected above using .iloc[]\n",
    "\n",
    "        \n",
    "        # 4. create and fit tree using using your subsetted X and y. Make sure to set max_depth using the \n",
    "        # max_d value from this function!\n",
    "        \n",
    "        # 5. add dictionary of model (tree) and array of features (features_index) that you made to forest\n",
    "        forest.append({\"tree\": tree, \"feats\": features_index})\n",
    "    \n",
    "    return(forest) \n",
    "\n",
    "### /YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Use `Forest()`\n",
    "Using `X_cols_df` and `y_df` (our training set) as your training set, call `Forest()` to build an ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data load\n",
    "\n",
    "X_cols_df = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/X_cols_df.csv\")\n",
    "y_df = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/y_df.csv\")\n",
    "X_cols_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "my_forest = ### call Forest function to create an ensemble/Random Forest using X_cols_df and y_df\n",
    "\n",
    "### /YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Comparing Ensemble to an Individual Model\n",
    "\n",
    "- Use the `ForestPredictor()` function below (which takes in the ensemble created by `Forest()` and data) to generate predictions for `X_cols_df2`, our *test* set.\n",
    "- Use the `ForestPredictor()` function below (which takes in the ensemble created by `Forest()` and data) to generate predictions for `X_cols_df`, our *train* set.\n",
    "- calculate the accuracies (train/test) of your ensemble.\n",
    "- calculate the accuracies (train/test) for ONE of your ensemble models by using `oneModel = my_forest[0]` to grab the first model of your ensemble. \n",
    "\n",
    "### 1.3.1\n",
    "In this example, does an ensemble method do *better* (in terms of train accuracy) than an individual decision tree? Explain how you figured this out.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2\n",
    "In this example, does an ensemble method do *better* (in terms of test accuracy) than an individual decision tree? Use `X_cols_df2` and `y_df2` as the test set.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForestPredictor(forest, X):\n",
    "\n",
    "    # takes in a list of dictionaries like below but longer, and returns predictons for them, similar to .predict()\n",
    "    # [\n",
    "    #     {\"trees\":DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "    #      max_depth=5, max_features=None, max_leaf_nodes=None,\n",
    "    #      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "    #      min_samples_leaf=1, min_samples_split=2,\n",
    "    #      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "    #      random_state=None, splitter='best'),\n",
    "    #     \"feats\": array([ 63, 101,  39, 133, 137])},\n",
    "\n",
    "    #  {\"trees\":DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "    #      max_depth=5, max_features=None, max_leaf_nodes=None,\n",
    "    #      min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "    #      min_samples_leaf=1, min_samples_split=2,\n",
    "    #      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "    #      random_state=None, splitter='best'),\n",
    "    #     \"feats\": array([ 63, 101,  39, 133, 137])}\n",
    "    # ]\n",
    "    import operator\n",
    "    from collections import Counter\n",
    "\n",
    "    ps = []\n",
    "\n",
    "    # get predictions from each model\n",
    "    for model in forest:\n",
    "        tree = model[\"tree\"]\n",
    "        X_sub = X.iloc[:, model[\"feats\"]]\n",
    "\n",
    "        p = tree.predict(X_sub)\n",
    "        ps.append(p)\n",
    "\n",
    "    ps = pd.DataFrame(ps)\n",
    "    \n",
    "    # get ensemble prediction for each data point\n",
    "    predictions = []\n",
    "    \n",
    "    for column_ind in range(0, ps.shape[1]):\n",
    "        ensemble_predict = ps.iloc[:,column_ind]\n",
    "        predictions.append(ensemble_predict.mode()[0])\n",
    "\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data load\n",
    "X_cols_df2 = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/X_cols_df2.csv\")\n",
    "y_df2 = pd.read_csv(\"https://raw.githubusercontent.com/cmparlettpelleriti/CPSC392ParlettPelleriti/master/Data/y_df2.csv\")\n",
    "\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# ForestPredict() will take your ensemble and use it to find the predicted values for X_cols_df2\n",
    "\n",
    "ensemble_predictions1 =  ### Call ForestPredictor using my_forest and X_cols_df2 (the test set)\n",
    "oneModel_predict1 = ### get predictions for X_cols_df2 (the test set) from oneModel (the first model in our ensemble)\n",
    "\n",
    "acc_e1 = accuracy_score(###) ### test accuracy for ensemble\n",
    "acc_o1 = accuracy_score(###) ### test accuracy for one model\n",
    "\n",
    "print(\"Test Acc (Ensemble) is: \", acc_e1)\n",
    "print(\"Test Acc (OneModel) is: \", acc_o1)\n",
    "\n",
    "### /YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "ensemble_predictions2 =  ### Call ForestPredictor using my_forest and X_cols_df (the training set)\n",
    "oneModel_predict2 = ### get predictions for X_cols_df (the training set) from oneModel (the first model in our ensemble)\n",
    "\n",
    "acc_e2 = accuracy_score(###) ### train accuracy for ensemble\n",
    "acc_o2 = accuracy_score(###) ### train accuracy for one model\n",
    "\n",
    "print(\"Train Acc (Ensemble) is: \", acc_e2)\n",
    "print(\"Train Acc (OneModel) is: \", acc_o2)\n",
    "\n",
    "### /YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Comparing Ensemble to an Individual ModelS\n",
    "\n",
    "- put the accuracy from your ENSEMBLE model in the code below\n",
    "- run the cell to see a histogram of the individual tree accuracies, and the (dashed line) ensemble accuracy.\n",
    "\n",
    "### 1.4.1\n",
    "Write down your thoughts about this graph. What patterns do you see between individual tree accuracies and ensemble accuracies?\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "ensemble_acc = ### put your ensemble accuracy here as a decimal\n",
    "\n",
    "### /YOUR CODE HERE ###\n",
    "\n",
    "allAcc = [accuracy_score(y_df2,my_forest[mod][\"tree\"].predict(X_cols_df2.iloc[:,my_forest[mod][\"feats\"]])) for mod in range(0,len(my_forest))]\n",
    "\n",
    "df = pd.DataFrame({\"acc\": allAcc, \"no\": range(0,len(my_forest))})\n",
    "(ggplot(df, aes(x = \"acc\")) +\n",
    " geom_histogram(color = \"black\", fill = \"lightblue\", binwidth = 0.025) +\n",
    " xlim([0,1]) + theme_minimal() + geom_vline(xintercept = ensemble_acc, linetype = \"dashed\", size = 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2\n",
    "How does the difference between individual tree accuracies and ensemble accuracies change when you change the number of predictors used in each tree? Try 2 and 249 below. Play around with `n_feat` yourself too!\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ghyQPx1N8dmU3MV4TrANvqNhGwnLni72\" width = 200px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = 249\n",
    "\n",
    "my_forest2 = Forest(X_cols_df, y_df, n_features = n_feat)\n",
    "\n",
    "ensemble_acc2 = accuracy_score(y_df2, ForestPredictor(my_forest2, X_cols_df2))\n",
    "\n",
    "\n",
    "allAcc2 = [accuracy_score(y_df2,my_forest2[mod][\"tree\"].predict(X_cols_df2.iloc[:,my_forest2[mod][\"feats\"]])) for mod in range(0,len(my_forest2))]\n",
    "\n",
    "df = pd.DataFrame({\"acc\": allAcc2, \"no\": range(0,len(my_forest2))})\n",
    "(ggplot(df, aes(x = \"acc\")) +\n",
    " geom_histogram(color = \"black\", fill = \"lightblue\", binwidth = 0.025) +\n",
    " xlim([0,1]) + theme_minimal() + geom_vline(xintercept = ensemble_acc2, linetype = \"dashed\", size = 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = 2\n",
    "\n",
    "\n",
    "my_forest3 = Forest(X_cols_df, y_df, n_features = n_feat)\n",
    "\n",
    "ensemble_acc3 = accuracy_score(y_df2, ForestPredictor(my_forest3, X_cols_df2))\n",
    "\n",
    "allAcc2 = [accuracy_score(y_df2,my_forest3[mod][\"tree\"].predict(X_cols_df2.iloc[:,my_forest3[mod][\"feats\"]])) for mod in range(0,len(my_forest3))]\n",
    "\n",
    "df = pd.DataFrame({\"acc\": allAcc2, \"no\": range(0,len(my_forest3))})\n",
    "(ggplot(df, aes(x = \"acc\")) +\n",
    " geom_histogram(color = \"black\", fill = \"lightblue\", binwidth = 0.025) +\n",
    " xlim([0,1]) + theme_minimal() + geom_vline(xintercept = ensemble_acc3, linetype = \"dashed\", size = 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRADING\n",
    "\n",
    "You'll be graded on the accuracy of your code, as well as the answers to the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Extra Credit:\n",
    "\n",
    "What do you think are some pros and cons of ensemble methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
